%!TEX root = main.tex
\chapter{Expert Review}
The expert evaluation was with a senior scientist at Sintef Information and Communication Technology\footnote{Sintef ICT: \url{http://www.sintef.no/home/Information-and-Communication-Technology-ICT/}}, which also works as adjunct associate professor at NTNU. The evaluator is an expert in the field of agile software development and knowledge management in software companies. He also had knowledge of GitHub and the use of it in agile development teams.  Apart from the expert review, the evaluator was never directly involved in our thesis.  \\
The evaluation performed was a type of expert walkthrough as described in \emph{Interaction Design - Beyond Human Computer Interaction}\cite{rogers2011interaction}. The evaluation we performed differs in that we also evaluate how the application can support agile software development teams and reflection through revisiting experiences. We presented the main features of the application and proceeded with a walkthrough of the application in its production state. The walkthrough consisted of typical tasks in our scenarios. After the walkthrough we had an open discussion with the evaluator on possible shortcomings or limitations, and also any advantages the evaluator had identified. 

% point in time we had not presented any of our thoughts or ideas about the
% further development of the application. We also held back on “defending”
% problems or limitations noticed that we knew where going to get fixed or implemented in the future. This was because we wanted a nuanced view of
% our application without the developers steering the discussion in any way.
% Next we asked the evaluator to present her initial ideas on how we could
% mprove the application with focus on reflection in learning, still without
% presenting any of our own thoughts about the subject.
% After this part, we had prepared a set of ideas and possibilities that could be
% used for enhancing the use of the application as a tool for reflection. Many
% of these were similar to the ones the evaluator already had presented in the
% previous part. We went through each of these ideas and discussed with the
% evaluator if they where feasible, any good or needed some improvement. The
% feedback on the application from the evaluator showed that we shared a lot
% of ideas on how we could further develop the application to better support
% reflection in learning.

% 
% # Feedback fra Torgeir:
% * Stille alternativer opp mot hverandre i rapporten, f.eks om de ser en nytte versus å kun bruke github. 
% * Belyser appen nye ting i forhold til vanlige retrospektiver?
% * Spørre gruppa hva de gjorde på tidligere retrospektiver, og om bruken av appen kan hjelpe. Spør de som ikke har deltatt at dersom de hadde brukt tags osv. hadde de sett nytten? Og da evt til hvilken grad.  
% * Spør: Hvorfor har de ikke brukt det? Tid? Features? Vanskelig? Var det i veien?

% ## Fordeler
% * Non-intrusive: Veldig bra
% * Er unikt: Han hadde ikke sett noe lignende verktøy
% * Er et kjent problem at man ikke husker alt, notes kan hjelpe men det kan bli mye data å analysere som går litt imot smidig. Viktig spørsmål å se om man husker mer ved bruk av appen, altså om man går glipp av noe uten å bruke appen. 
%* Finne feilprioriteringer, ofte er det feilvurderinger av hva som er viktig å gjøre. Oftest gjøres det som utviklerne vil og ikke kunden. Med appen kan man se tendenser til mye jobbing på feil ting. Samt. at man ser at milestones går overdue. 
%* Koble ting opp mot teorimodell: Kompetanseoverlapp. Sitter noen mye alene? Tagclouden kan vise slike tendenser.
%* Re-work: Oppdage dette, vi har muligheter til å oppdage mye gjenåpninger på issues og forklare dette. Mye jobbing med samme ting kan oppdages i appen. 

%## Utfordringer
%* Får man noe nyttig utav det
%* Få personer til å faktisk bruke tags i hverdagen. 
%* Generelt vanskelig terskel å få folk til å bruke verktøy. -> Rogers curve-diagram. 
%* Det vil være folk som ikke vil bidra like mye, early adopters vs laggers. 
%* Forskjellig nivå på utviklere. Noen vil dominere commit statistikken, men betyr det da at de er viktigere enn de andre? (Som kanskje gjør andre viktige ting i prosjektet). Det kan gi feil totalbilde. 

%## Features
%* Ha deler av kildekoden i peaceful, en slags "hva har skjedd" feature. Overlapper litt med github
%* Burndown chart. Har github noe lignende kanskje? sjekk

%## Studier
%* Vitner husker ofte feil i rettsaker -> hukommelse er ikke bombesikker/til å stole på alltid. Derfor lurt å ta ferske erfaringer

%### Related Work:
%* Hackystat : https://code.google.com/p/hackystat/